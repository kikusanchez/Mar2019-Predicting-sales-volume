}
}
word_fun(data=m,keyword = "FACI")
word_fun(data=m,keyword = "FOAM")
word_fun<-function(data,keyword){
for (i in 1:ncol(data)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
print(paste("TRUE at column",(i)))
}
else{print("FALSE")}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
print("TRUE")
}
else{print("FALSE")}
}
}
word_fun(data=m,keyword = "FOAM")
word_fun<-function(data,keyword){
for (i in 1:ncol(data)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
print(paste("TRUE at column",(i)))
}
else{print("FALSE")}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
print(paste("TRUE at row",(y)))
}
else{print("FALSE")}
}
}
word_fun(data=m,keyword = "FACI")
exist<-0
exist<-1
exist<-1
word_fun<-function(data,keyword){
exist<-0
for (i in 1:ncol(data)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
exist<-1
print(paste("TRUE at column",(i)))
}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
exist<-1
print(paste("TRUE at row",(y)))
}
}
if (exist==0){
print("FALSE")
}
}
word_fun(data=m,keyword = "FACI")
word_fun(data=m,keyword = "KIKO")
readline(prompt = "Enter a word")
keyword<-readline(prompt = "Enter a word")
for (i in 1:ncol(data)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
exist<-1
print(paste("TRUE at column",(i)))
}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
exist<-1
print(paste("TRUE at row",(y)))
}
}
if (exist==0){
print("FALSE")
}
}
word_fun(data=m,keyword = "KIKO")
word_fun<-function(data){
keyword<-readline(prompt = "Enter a word")
exist<-0
for (i in 1:ncol(data)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
exist<-1
print(paste("TRUE at column",(i)))
}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
exist<-1
print(paste("TRUE at row",(y)))
}
}
if (exist==0){
print("FALSE")
}
}
word_fun(data=m)
word_fun<-function(data){
keyword<-readline(prompt = "Enter a word: ")
exist<-0
for (i in 1:ncol(data)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
exist<-1
print(paste("TRUE at column",(i)))
}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
exist<-1
print(paste("TRUE at row",(y)))
}
}
if (exist==0){
print("FALSE")
}
}
word_fun(data=m)
#function (version 2)
#if exist=TRUE
word_fun<-function(data, keyword){
exist<-0
for (i in 1:ncol(data,keyword)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
exist<-1
print(paste("TRUE at column",(i)))
}
}
for (y in 1:nrow(data, keyword)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
exist<-1
print(paste("TRUE at row",(y)))
}
}
if (exist==0){
print("FALSE")
}
}
word_fun(data=m, keyword="FOAM")
#function (version 2)
#if exist=TRUE
word_fun<-function(data, keyword){
exist<-0
for (i in 1:ncol(data,keyword)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
exist<-1
print(paste("TRUE at column",(i)))
}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
exist<-1
print(paste("TRUE at row",(y)))
}
}
if (exist==0){
print("FALSE")
}
}
word_fun(data=m, keyword="FOAM")
#function (version 2)
#if exist=TRUE
word_fun<-function(data, keyword){
exist<-0
for (i in 1:ncol(data)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
exist<-1
print(paste("TRUE at column",(i)))
}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
exist<-1
print(paste("TRUE at row",(y)))
}
}
if (exist==0){
print("FALSE")
}
}
word_fun(data=m, keyword="FOAM")
#function (version 3)
#adding a 'prompt' asking for writing a word
word_fun<-function(data){
keyword<-readline(prompt = "Enter a word: ")
exist<-0
for (i in 1:ncol(data)) {
combi_cols<- paste (data[,i],collapse = "")
if (grepl(keyword,combi_cols)){
exist<-1
print(paste("TRUE at column",(i)))
}
}
for (y in 1:nrow(data)) {
combi_rows<-paste(data[y,], collapse="")
if (grepl(keyword,combi_rows)){
exist<-1
print(paste("TRUE at row",(y)))
}
}
if (exist==0){
print("FALSE")
}
}
word_fun(data=m)
#### 0. INCLUDES ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi, dplyr,magrittr, tidyr, reshape2, readxl, stringi,
ggplot2,caret,corrplot,rpart,e1071)
# Setwd (1ยบ current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
#Data sets
existing<-read.csv("../blackwells_multiple_regression/datasets/existingproductattributes2017.csv")
new<-read.csv("../blackwells_multiple_regression/datasets/newproductattributes2017.csv")
#removing attribute (column)
existing$BestSellersRank<-NULL
#removing attribute (column)
existing$BestSellersRank<-NULL
#removing outliers regarding volume (productNum 198 & 150)
existing_out<-existing[-c(50,73),]
#dummify the data
exis_dummy <- dummyVars(" ~ .", data = existing_out)
readyData<-data.frame(predict(exis_dummy,newdata = existing_out))
#### 3. MODELING ####
#creating training and testing sets
set.seed(123)
inTraining<-createDataPartition(readyData$Volume, p=.75, list = FALSE)
training<-readyData[inTraining,]
testing<-readyData[-inTraining,]
#4 fold (number=4) cross validation (repeatedcv)
cvtraincontrol <- trainControl(method = "repeatedcv", number = 4, repeats = 2)
# plotting the results
ggplot(testing_errors,
aes(pred_rf_all,Volume))+
geom_point(color="red")+
geom_smooth()
# plotting the results
ggplot(testing_errors,
aes(pred_rf_all,Volume))+
geom_point(color="red")+
geom_smooth()
#duplicating the testing size to include the errors in columns
testing_errors<-testing
#create columns with the best prediction
#results column
testing_errors$pred_rf_all<-Pred_rf_all
#main error column
testing_errors$main_error<- testing_errors$Volume - testing_errors$pred_rf_all
#relative error
testing_errors$rel_error<- abs((testing_errors$pred_rf_all - testing_errors$Volume) / testing_errors$Volume)*100
# plotting the results
ggplot(testing_errors,
aes(pred_rf_all,Volume))+
geom_point(color="red")+
geom_smooth()
# plotting the results
ggplot(testing_errors,
aes(pred_rf_all,Volume))+
geom_point(color="red")+
geom_smooth()
# plotting the results
ggplot(testing_errors,
aes(Volume,pred_rf_all))+
geom_point(color="red")+
geom_smooth()
#create columns with the best prediction
#results column
testing_errors$pred_rf_all<-Pred_rf_all
#### 3.1 Random Forest - all variables ####
#creating the train Random Forest Regression model with .= all the variables of readyData_rel
rf_all <- train(Volume~., data = training, method = "rf", trControl=cvtraincontrol, tuneLength=5)
#training results from a Random Forest model with all attributes
rf_all
#creating the prediction of the model applied to the testing size
Pred_rf_all<-predict(rf_all,testing)
#creating the train Random Forest Regression model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
rf_3att <- train(Volume~x4StarReviews+x3StarReviews+PositiveServiceReview, data = training, method = "rf", trControl=cvtraincontrol, tuneGrid=rfgrid)
#training results from a Random Forest model with 3 attributes:
rf_3att
#creating the prediction of the model applied to the testing size
Pred_rf_3att<-predict(rf_3att,testing)
#creating the prediction of the model applied to the testing size
Pred_rf_3att<-predict(rf_3att,testing)
#creating the train Random Forest Regression model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
rf_3att <- train(Volume~x4StarReviews+x3StarReviews+PositiveServiceReview, data = training, method = "rf", trControl=cvtraincontrol, tuneGrid=rfgrid)
#### 3.1.1 Random forest - 3 attributes ####
#data.frame for manual tuning of the grid --> number of grid = number of variables
rfgrid<-expand.grid(mtry=c(1,2,3))
#creating the train Random Forest Regression model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
rf_3att <- train(Volume~x4StarReviews+x3StarReviews+PositiveServiceReview, data = training, method = "rf", trControl=cvtraincontrol, tuneGrid=rfgrid)
#training results from a Random Forest model with 3 attributes:
rf_3att
#creating the prediction of the model applied to the testing size
Pred_rf_3att<-predict(rf_3att,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_rf_3att
#### 3.1.2 Random forest - 2 attributes ####
#data.frame for manual tuning of the grid --> number of grid = number of variables
rfgrid2<-expand.grid(mtry=c(1,2))
#creating the train Random Forest Regression model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
rf_2att <- train(Volume~x4StarReviews+PositiveServiceReview, data = training, method = "rf", trControl=cvtraincontrol, tuneGrid=rfgrid2)
#training results from a Random Forest model with 3 attributes:
rf_2att
#creating the prediction of the model applied to the testing size
Pred_rf_2att<-predict(rf_2att,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_rf_2att
#### 3.2 knn - all variables ####
knnFit_all <- train(Volume ~ ., data = training, method = "knn", trControl = cvtraincontrol, tuneLength=20)
#training results from a knn model with all attributes:
knnFit_all
#creating the prediction of the model applied to the testing size
Pred_knn_all<-predict(knnFit_all,testing)
#prediction results applied to testing size from a knn model with all variables
Pred_knn_all
#duplicating the testing size to include the errors in columns
testing_errors<-testing
#create columns with the best prediction
#results column
testing_errors$pred_rf_all<-Pred_rf_all
#main error column
testing_errors$main_error<- testing_errors$Volume - testing_errors$pred_rf_all
#relative error
testing_errors$rel_error<- abs((testing_errors$pred_rf_all - testing_errors$Volume) / testing_errors$Volume)*100
# plotting the results
ggplot(testing_errors,
aes(Volume,pred_rf_all))+
geom_point(color="red")+
geom_smooth()
# plotting the results
ggplot(testing_errors,
aes(Volume,main_errorl))+
geom_point(color="red")+
geom_smooth()
# plotting the results
ggplot(testing_errors,
aes(Volume,main_error))+
geom_point(color="red")+
geom_smooth()
# plotting the results
ggplot(testing_errors,
aes(main_error,Volume))+
geom_point(color="red")+
geom_smooth()
# plotting the results
ggplot(testing_errors,
aes(Volume,main_error))+
geom_point(color="red")+
geom_smooth()
#relative error
ggplot(testing_errors,
aes(Volume,relative_error))+
geom_point(color="red")+
geom_smooth()
#relative error
ggplot(testing_errors,
aes(Volume,rel_error))+
geom_point(color="red")+
geom_smooth()
#outliers for product types based on volume
ggplot(existing,
aes(x=existing$ProductType,y=existing$Volume))+
geom_boxplot(outlier.size = 2, outlier.colour = "red")
#outliers for product types based on volume
ggplot(existing,
aes(x=ProductType,y=Volume))+
geom_boxplot(outlier.size = 2, outlier.colour = "red")
#scatter Volume vs 4stars
ggplot(existing_out,
aes(x=x4StarReviews,y=Volume))+
geom_point(color="blue")+
geom_smooth()
names (existing_out)
#scatter Volume vs positiveService
ggplot(existing_out,
aes(x=PositiveServiceReview,y=Volume))+
geom_point(color="blue")+
geom_smooth()
#plotting histograms to see the distribution of numerical or integer variables
ggplot(existing,
aes(x=existing$Price))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (product 102)
#### 2. PLOTTING ####
#### 2.1 all variables ####
#plotting bars to see the distribution of categorical variables
ggplot(existing,
aes(x=ProductType))+
geom_bar(color="blue", fill="yellow")
library(caret)
library(readr)
library(rstudioapi)
library(e1071)
library(dplyr)
library(rpart)
#current_path = getActiveDocumentContext()$path
#setwd(dirname(current_path))
#setwd("..")
#rm(current_path)
EP <- read.csv( file ="C:/Users/Kiko Sรกnchez/Desktop/Ubiqum/Course 2/Task 3/multiple_regression/blackwells_multiple_regression/datasets/existingproductattributes2017.csv" , header = TRUE , sep = ',')
NP <- read.csv(file = "C:/Users/Kiko Sรกnchez/Desktop/Ubiqum/Course 2/Task 3/multiple_regression/blackwells_multiple_regression/datasets/newproductattributes2017.csv", header = TRUE , sep =',')
# plotting the results
#main error
ggplot(testing_errors,
aes(main_error,Volume))+
geom_point(color="red")+
geom_smooth()
View(testing_errors)
#relative error
ggplot(testing_errors,
aes(Volume,rel_error))+
geom_point(color="red")+
geom_smooth()
# plotting the results
#absolute error
ggplot(testing_errors,
aes(main_error,Volume))+
geom_point(color="red")+
geom_smooth()
#relative error
ggplot(testing_errors,
aes(rel_error,Volume))+
geom_point(color="red")+
geom_smooth()
# plotting the results
#absolute error
ggplot(testing_errors,
aes(Volume,main_error))+
geom_point(color="red")+
geom_smooth()
#relative error
ggplot(testing_errors,
aes(Volume,relative_error))+
geom_point(color="red")+
geom_smooth()
#relative error
ggplot(testing_errors,
aes(Volume,rel_error))+
geom_point(color="red")+
geom_smooth()
#### 3.1 Random Forest - all variables ####
#creating the train Random Forest Regression model with .= all the variables of readyData_rel
rf_all <- train(Volume~., data = training, method = "rf", trControl=cvtraincontrol, tuneLength=5)
#training results from a Random Forest model with all attributes
rf_all
#creating the prediction of the model applied to the testing size
Pred_rf_all<-predict(rf_all,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_rf_all
summary(Pred_rf_all)
#comparing prediction with real values
postResample(Pred_rf_all,testing$Volume)
#### 3.1.2 Random forest - 2 attributes ####
#data.frame for manual tuning of the grid --> number of grid = number of variables
rfgrid2<-expand.grid(mtry=c(1,2))
#creating the train Random Forest Regression model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
rf_2att <- train(Volume~x4StarReviews+PositiveServiceReview, data = training, method = "rf", trControl=cvtraincontrol, tuneGrid=rfgrid2)
#training results from a Random Forest model with 3 attributes:
rf_2att
#creating the prediction of the model applied to the testing size
Pred_rf_2att<-predict(rf_2att,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_rf_2att
summary(Pred_rf_2att)
#comparing prediction with real values:
postResample(Pred_rf_2att,testing$Volume)
#function to test different models with different attributes
#SELECT MODELS
Models <- c("lm","rf", "knn", "svmLinear")
#SELECT FEATURES
Features <- c("Volume ~ .",
"Volume ~ x4StarReviews + PositiveServiceReview + x3StarReviews",
"Volume ~ x4StarReviews + PositiveServiceReview")
#RUN THE MODELS
compare.model <- c()
for(i in Models) {
for (y in Features) {
print(i)
model <- train(formula(y), data = training, method = i)
print(model$results)
pred <- predict(model, newdata = testing)
pred.metric <- postResample(testing$Volume, pred)
compare.model <- cbind(compare.model , pred.metric)
}
}
