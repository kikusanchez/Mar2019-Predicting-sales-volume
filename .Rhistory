library(readr)
DatasetName<- read.csv("cars.csv file")
DatasetName<- read.csv("cars.csv file")
cars <- read.csv("~/R/cars.csv")
View(cars)
DatasetName<- read.csv("cars.csv file")
setwd('C:\Users\Kiko Sánchez\Desktop\Ubiqum\R')
setwd(C:\Users\Kiko Sánchez\Desktop\Ubiqum\R)
setwd("C:\Users\Kiko Sánchez\Desktop\Ubiqum\R")
setwd C:\Users\Kiko Sánchez\Desktop\Ubiqum\R
setwd(C:\Users\Kiko Sánchez\Desktop\Ubiqum\R)
setwd("C:\Users\Kiko Sánchez\Desktop\Ubiqum\R")
setwd('C:\Users\Kiko Sánchez\Desktop\Ubiqum\R')
setwd("'C:\Users\Kiko Sánchez\Desktop\Ubiqum\R'")
setwd(C:\Users\Kiko Sánchez\Desktop\Ubiqum\R)
setwd("C:/Users/Kiko Sánchez/Desktop/Ubiqum/R")
> setwd("C:/Users/Kiko Sánchez/Desktop/Ubiqum/R")
setwd('C:\Users\Kiko Sánchez\Desktop\Ubiqum\R')
setwd(C:/Users/Kiko Sánchez/Desktop/Ubiqum/R)
> setwd(C:/Users/Kiko Sánchez/Desktop/Ubiqum/R)
getwd()
DatasetName<- read.csv("cars.csv file")
cars<- read.csv("cars.csv file")
DatasetName<- read.csv("cars.csv")
View(DatasetName)
View(DatasetName)
View(DatasetName)
RTutorial1<- read.csv("cars.csv")
attributes(RTutorial1)#List your attributes within your data set.
summary(RTutorial1)
str(RTutorial1)
names(RTutorial1)
Tutorial1$name.of.car
str(RTutorial1)
RTutorial1$name.of.car
summary(RTutorial1)
View(RTutorial1)
summary(RTutorial1)
summary(RTutorial1)
hist(RTutorial1$name.of.car)
hist(RTutorial1$speed.of.car)
summary(RTutorial1)
hist(RTutorial1$speed.of.car)
hist(RTutorial1$speed.of.car)
summary(RTutorial1)
hist(RTutorial1$distance.of.car)
hist(RTutorial1$distance.of.car)
View(RTutorial1)
rtutorial1<- read.csv(cars)
rtutorial1<- read.csv("cars")
rtutorial1<- read.csv("cars.csv")
plot(rtutorial1$name.of.car,rtutorial1$speed.of.car)
qqnorm(rtutorial1$speed.of.car)
rtutorial1$name.of.car<-as.data.frame.integer()
rtutorial1$name.of.car<-as.numeric(x,10)
rtutorial1$name.of.car<-as.integer(x,1-10)
rtutorial1$name.of.car<-as.integer(x)
rtutorial1$name.of.car<-as.numeric(x,... = )
rtutorial1$name.of.car<-as.numeric(x,...)
rtutorial1$name.of.car<-as.numeric
rtutorial1$name.of.car<-as.numeric(rtutorial1$name.of.car)
View(rtutorial1)
library(readr)
cars <- read_csv("C:/Users/Kiko Sánchez/Desktop/Ubiqum/R/cars.csv")
View(cars)
View(rtutorial1)
View(cars)
names(rtutorial1)<-c("name","speed","distance")
View(rtutorial1)
names(cars)<-c("name","speed","distance")
View(cars)
save.image("C:/Users/Kiko Sánchez/Desktop/Ubiqum/R/rtutorial1.RData")
summary(rtutorial1)
is.na(rtutorial1)
na.omit(rtutorial1)
rtutorial1$speed[is.na rtutorial1$speed]<-mean(rtutorial1$speed,na.rm = TRUE)
rtutorial1$speed[is.na(rtutorial1$speed)]<-mean(rtutorial1$speed,na.rm = TRUE)
rtutorial1$speed[is.na(rtutorial1$speed)]<-mean(rtutorial1$speed,na.rm = TRUE)
trainSize<-round(nrow(rtutorial1)*0.7)
testSize<-nrow(rtutorial1)-trainSize
trainSize
testSize
training_indices<-sample(seq_len(nrow(rtutorial1)),size = trainSize)
trainset<-rtutorial1[training_indices,]
testset<-rtutorial1[-training_indices,]
Regdistance<-lm(distance~ speed, trainset)
summary(Regdistance)
predictdistance<-(Regdistance,testset)
predictdistance<- predict(Regdistance,testset)
predictdistance
View(testset)
View(testset)
View(trainset)
View(testset)
View(trainset)
View(trainset)
View(testset)
View(trainset)
training_indices
install.packages(readr)
R--vanilla
R --vanilla
> .Last <- function() system("R --vanilla")
> q("no")
R --Vanilla
install.packages(readr)
?Geometric
install.packages("caret", dependencies = c("Depends", "Suggests"))
#display the relationship between age, salary & brand
ggplot(Complete,
aes(x=age, y=salary, col=brand)) +
geom_point() +
geom_smooth()
library(caret)
library(ggplot2)
library(tidyverse)
library(ggthemes)
library(plotly)
library(highcharter)
Complete<-read.csv("C:/Users/Kiko Sánchez/Desktop/Ubiqum/Course 2/Task 2/datasets/CompleteResponses.csv")
#barplot of the brand
ggplot(Complete,
aes(x=brand,fill=brand))+
geom_bar()
#histogram of the salary
ggplot(Complete,
aes(x=salary))+
geom_histogram(bins = 10)
#many salary histograms as levels of education you have
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 20)+
facet_wrap(Complete$elevel)
#combination with brand and salary
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 20)
#to show x values in all the plots (scales="free_x")
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 20)+
facet_wrap(Complete$elevel, scales = "free_x")
#display the relationship between age, salary & brand
ggplot(Complete,
aes(x=age, y=salary, col=brand)) +
geom_point() +
geom_smooth()
#display the relationship between age, salary & brand
ggplot(Complete,
aes(x=age, y=salary, col=brand)) +
geom_point() +
geom_smooth()+
scale_y_continuous(labels = scales::percent)
#to show x values in all the plots (scales="free_x")
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 20)+
facet_wrap(Complete$elevel, scales = "free_x")
#combination with brand and salary
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 20)
#barplot of the brand
ggplot(Complete,
aes(x=brand,fill=brand))+
geom_bar()
#combination with brand and salary
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 20)
#combination with brand and salary
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 10)
#### Highcharter ####
#brand pie chart
newdf<-Complete%>%
select(brand) %>%
group_by(brand) %>%
summarise(n=n())
highchart() %>%
hc_chart(type = "pie") %>%
hc_add_series_labels_values(labels = newdf$brand, values = newdf$n)
#### Plotly ####
P<-plot_ly(data = Complete, x = ~age, y = ~salary, color=~brand)
P
View(Complete)
#education level
Complete$elevel<-factor(Complete$elevel,
levels = c(0,1,2,3,4),
labels = c("Basic education", "High School", "Some College", "College Degree", "PHD"))
#cars brands
Complete$car<-factor(Complete$car,
levels = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20),
labels = c("BMW","Buick", "Cadillac", "Chevrolet","Chrysler","Dodge","Ford","Honda","Hyundai","Jeep","Kia","Lincoln","Mazda","Mercedes","Mitsubishi","Nissan","Ram","Subaru","Toyota","None"))
#regions
Complete$zipcode <- factor(Complete$zipcode,
levels = c(0,1,2,3,4,5,6,7,8),
labels = c("New England","Mid Atlantic","East North Central","West North Central","South Atlantic","East South Central","West South Central","Mountain","Pacific"))
#computer brands
Complete$brand<-factor(Complete$brand,
levels = c(0,1),
labels = c("Acer","Sony"))
#combination with brand and salary
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 10)
#combination with brand and salary
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 10)+
geom_text(aes(label = paste0(round(100 * percent, 1), "%")), vjust = -0.25)
#combination with brand and salary
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 10)+
geom_text(aes(label = paste0(round(100 * salary, 1), "%")), vjust = -0.25)
#combination with brand and salary
ggplot(Complete,
aes(x=salary,fill=brand))+
geom_histogram(color="black", bins = 10)+
geom_text(aes(y=salary, label = paste0(round(100 * salary, 1), "%")), vjust = -0.25)
#### 0. INCLUDES ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi, dplyr,magrittr, tidyr, reshape2, readxl, stringi,
ggplot2,caret,corrplot,rpart,e1071)
#### 0. INCLUDES ####
#Load Libraries: p_load can install, load,  and update packages
if(require("pacman")=="FALSE"){
install.packages("pacman")
}
pacman::p_load(rstudioapi, dplyr,magrittr, tidyr, reshape2, readxl, stringi,
ggplot2,caret,corrplot,rpart,e1071)
# Setwd (1º current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
#Data sets
existing<-read.csv("../multiple_regression/blackwells_multiple_regression/datasets/existingproductattributes2017.csv")
new<-read.csv("../multiple_regression/blackwells_multiple_regression/datasets/newproductattributes2017.csv")
str(existing)
#### 1. PRE-PROCESSING ####
#deleting attributes with NA values
summary(existing) # $BestSellersRank NA's:15
#removing attribute (column)
existing$BestSellersRank<-NULL
#removing outliers regarding volume (productNum 198 & 150)
existing_out<-existing[-c(50,73),]
#dummify the data
exis_dummy <- dummyVars(" ~ .", data = existing_out)
readyData<-data.frame(predict(exis_dummy,newdata = existing_out))
#### 1.1 Correlation matrices ####
#all variables
corr_all<-cor(readyData)
corr_all
corrplot(corr_all)
?corrplot
#removing lower and higher correlate attributes from data set
#creating a new data frame to remove irrelevant attributes
readyData_rel<-readyData
#removing irrelevant attributes
readyData_rel$Price<-NULL
readyData_rel$x5StarReviews<-NULL
readyData_rel$x2StarReviews<-NULL
readyData_rel$x1StarReviews<-NULL
readyData_rel$NegativeServiceReview<-NULL
readyData_rel$Recommendproduct<-NULL
readyData_rel$ShippingWeight<-NULL
readyData_rel$ProductDepth<-NULL
readyData_rel$ProductWidth<-NULL
readyData_rel$ProductHeight<-NULL
readyData_rel$ProfitMargin<-NULL
#correlation matrix with only relevant attributes
corr_rel<-cor(readyData_rel)
corr_rel
corrplot(corr_rel)
#### 1.2 decision tree ####
#decision tree with only relevant attributes
fit<-rpart(Volume~.,method = "class",data = readyData_rel)
fit
plot(fit)
#### 2. PLOTTING ####
#plotting bars to see the distribution of categorical variables
ggplot(existing,
aes(x=ProductType))+
geom_bar(color="blue", fill="yellow")
#plotting histograms to see the distribution of numerical or integer variables
ggplot(existing,
aes(x=existing$Price))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (product 102)
ggplot(existing,
aes(x=existing$x5StarReviews))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (products 198, 150)
ggplot(existing,
aes(x=existing$x4StarReviews))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (product 150)
ggplot(existing,
aes(x=existing$x3StarReviews))+
geom_histogram(color="blue", fill="cyan", bins = 10)
ggplot(existing,
aes(x=existing$x2StarReviews))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (product 123)
ggplot(existing,
aes(x=existing$x1StarReviews))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (product 123)
ggplot(existing,
aes(x=existing$PositiveServiceReview))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (product 150)
ggplot(existing,
aes(x=existing$NegativeServiceReview))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (product 123)
ggplot(existing,
aes(x=existing$Recommendproduct))+
geom_histogram(color="blue", fill="cyan", bins = 10)
ggplot(existing,
aes(x=existing$BestSellersRank))+
geom_histogram(color="blue", fill="cyan", bins = 10)
ggplot(existing,
aes(x=existing$ShippingWeight))+
geom_histogram(color="blue", fill="cyan", bins = 10)
ggplot(existing,
aes(x=existing$ProductDepth))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (product 153)
ggplot(existing,
aes(x=existing$ProductWidth))+
geom_histogram(color="blue", fill="cyan", bins = 10)
ggplot(existing,
aes(x=existing$ProductHeight))+
geom_histogram(color="blue", fill="cyan", bins = 10)
ggplot(existing,
aes(x=existing$Volume))+
geom_histogram(color="blue", fill="cyan", bins = 10) ## outliers here? (products 198, 150)
#outliers for product types based on volume
ggplot(existing,
aes(x=existing$ProductType,y=existing$Volume))+
geom_boxplot(outlier.size = 2, outlier.colour = "red")
#create a data set cointaining only PC (subset of ProductType)
only_pc <- existing[which(existing$ProductType == "PC"),names(existing)]
ggplot(only_pc,
aes(x=ProductType,y=Volume))+
geom_boxplot(outlier.size = 2, outlier.colour = "red")
#### 3. MODELING ####
#creating training and testing sets
set.seed(123)
inTraining<-createDataPartition(readyData_rel$Volume, p=.75, list = FALSE)
training<-readyData_rel[inTraining,]
testing<-readyData_rel[-inTraining,]
#4 fold (number=4) cross validation (repeatedcv)
cvtraincontrol <- trainControl(method = "repeatedcv", number = 4, repeats = 1)
#### 3.1 Random Forest - all variables ####
#creating the train Random Forest Regression model with .= all the variables of readyData_rel
rf_all <- train(Volume~., data = training, method = "rf", trControl=cvtraincontrol, tuneLength=5)
#training results from a Random Forest model with all attributes:
#mtry 16, rmse 130.5218, Rsquared 0.9462132,MAE 68.88377
rf_all
#creating the prediction of the model applied to the testing size
Pred_rf_all<-predict(rf_all,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_rf_all
summary(Pred_rf_all)
#comparing prediction with real values: RMSE 246.7253742, Rsquared 0.8687247, MAE 140.6123111
postResample(Pred_rf_all,testing$Volume)
summary(postResample(Pred_rf_all,testing$Volume))
#### 3.1.1 Random forest - with 3 relevant attributes ####
#data.frame for manual tuning of the grid --> number of grid = number of variables
rfgrid<-expand.grid(mtry=c(1,2,3))
#creating the train Random Forest Regression model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
system.time(rf_rel <- train(Volume~x4StarReviews+x3StarReviews+PositiveServiceReview, data = training, method = "rf", trControl=cvtraincontrol, tuneGrid=rfgrid))
#training results from a Random Forest model with 3 attributes:
#mtry 2, rmse 190.5956, Rsquared 0.8800054,MAE 91.62429
rf_rel
#creating the prediction of the model applied to the testing size
Pred_rf_rel<-predict(rf_rel,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_rf_rel
summary(Pred_rf_rel)
#comparing prediction with real values: RMSE 252.254184, Rsquared 0.871624, MAE 150.044185
postResample(Pred_rf_rel,testing$Volume)
summary(postResample(Pred_rf_all,testing$Volume))
#### 3.2 knn - all variables ####
knnFit_all <- train(Volume ~ ., data = training, method = "knn", trControl = cvtraincontrol, tuneLength=20)
#training results from a knn model with all attributes:
#k=5, rmse 268.6125, Rsquared 0.8096786,MAE 132.5638
knnFit_all
#creating the prediction of the model applied to the testing size
Pred_knn_all<-predict(knnFit_all,testing)
#prediction results applied to testing size from a knn model with all variables
Pred_knn_all
summary(Pred_knn_all)
#comparing prediction with real values: RMSE 352.112103, Rsquared 0.777198, MAE 205.688889
postResample(Pred_knn_all,testing$Volume)
summary(postResample(Pred_knn_all,testing$Volume))
#### 3.3 knn - 3 attributes ####
#creating the train knn model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
system.time(knn_rel <- train(Volume~x4StarReviews+x3StarReviews+PositiveServiceReview, data = training, method = "knn", trControl=cvtraincontrol))
#training results from a knn model with 3 attributes:
#k=5, rmse 262.8981, Rsquared 0.8650510,132.9468
knn_rel
#creating the prediction of the model applied to the testing size
Pred_knn_rel<-predict(knn_rel,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_knn_rel
summary(Pred_knn_rel)
#comparing prediction with real values: RMSE 315.1408050, Rsquared 0.8164688, MAE 181.1566138
postResample(Pred_knn_rel,testing$Volume)
summary(postResample(Pred_knn_all,testing$Volume))
# Setwd (1º current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
#Data sets
existing<-read.csv("../multiple_regression/blackwells_multiple_regression/datasets/existingproductattributes2017.csv")
pacman::p_load(rstudioapi, dplyr,magrittr, tidyr, reshape2, readxl, stringi,
ggplot2,caret,corrplot,rpart,e1071)
# Setwd (1º current wd where is the script, then we move back to the
# general folder)
current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
#Data sets
existing<-read.csv("../multiple_regression/blackwells_multiple_regression/datasets/existingproductattributes2017.csv")
#Data sets
existing<-read.csv("./multiple_regression/blackwells_multiple_regression/datasets/existingproductattributes2017.csv")
#Data sets
existing<-read.csv("../blackwells_multiple_regression/datasets/existingproductattributes2017.csv")
new<-read.csv("../blackwells_multiple_regression/datasets/newproductattributes2017.csv")
#removing attribute (column)
existing$BestSellersRank<-NULL
#removing outliers regarding volume (productNum 198 & 150)
existing_out<-existing[-c(50,73),]
#dummify the data
exis_dummy <- dummyVars(" ~ .", data = existing_out)
readyData<-data.frame(predict(exis_dummy,newdata = existing_out))
#all variables
corr_all<-cor(readyData)
#removing lower and higher correlate attributes from data set
#creating a new data frame to remove irrelevant attributes
readyData_rel<-readyData
#decision tree with only relevant attributes
fit<-rpart(Volume~.,method = "class",data = readyData_rel)
fit
plot(fit)
#### 3. MODELING ####
#creating training and testing sets
set.seed(123)
inTraining<-createDataPartition(readyData_rel$Volume, p=.75, list = FALSE)
training<-readyData_rel[inTraining,]
testing<-readyData_rel[-inTraining,]
#4 fold (number=4) cross validation (repeatedcv)
cvtraincontrol <- trainControl(method = "repeatedcv", number = 4, repeats = 1)
#### 3.1 Random Forest - all variables ####
#creating the train Random Forest Regression model with .= all the variables of readyData_rel
rf_all <- train(Volume~., data = training, method = "rf", trControl=cvtraincontrol, tuneLength=5)
#training results from a Random Forest model with all attributes:
#mtry 16, rmse 130.5218, Rsquared 0.9462132,MAE 68.88377
rf_all
#creating the prediction of the model applied to the testing size
Pred_rf_all<-predict(rf_all,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_rf_all
summary(Pred_rf_all)
#comparing prediction with real values: RMSE 246.7253742, Rsquared 0.8687247, MAE 140.6123111
postResample(Pred_rf_all,testing$Volume)
#### 3.1.1 Random forest - with 3 relevant attributes ####
#data.frame for manual tuning of the grid --> number of grid = number of variables
rfgrid<-expand.grid(mtry=c(1,2,3))
#creating the train Random Forest Regression model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
system.time(rf_rel <- train(Volume~x4StarReviews+x3StarReviews+PositiveServiceReview, data = training, method = "rf", trControl=cvtraincontrol, tuneGrid=rfgrid))
#training results from a Random Forest model with 3 attributes:
#mtry 2, rmse 190.5956, Rsquared 0.8800054,MAE 91.62429
rf_rel
#creating the prediction of the model applied to the testing size
Pred_rf_rel<-predict(rf_rel,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_rf_rel
summary(Pred_rf_rel)
#comparing prediction with real values: RMSE 252.254184, Rsquared 0.871624, MAE 150.044185
postResample(Pred_rf_rel,testing$Volume)
#### 3.2 knn - all variables ####
knnFit_all <- train(Volume ~ ., data = training, method = "knn", trControl = cvtraincontrol, tuneLength=20)
#training results from a knn model with all attributes:
#k=5, rmse 268.6125, Rsquared 0.8096786,MAE 132.5638
knnFit_all
#creating the prediction of the model applied to the testing size
Pred_knn_all<-predict(knnFit_all,testing)
#prediction results applied to testing size from a knn model with all variables
Pred_knn_all
summary(Pred_knn_all)
#comparing prediction with real values: RMSE 352.112103, Rsquared 0.777198, MAE 205.688889
postResample(Pred_knn_all,testing$Volume)
#creating the train knn model with 3 and 4 stars and positive service
#system time wrapper. system.time()is used to measure process execution time
system.time(knn_rel <- train(Volume~x4StarReviews+x3StarReviews+PositiveServiceReview, data = training, method = "knn", trControl=cvtraincontrol))
knn_rel
#creating the prediction of the model applied to the testing size
Pred_knn_rel<-predict(knn_rel,testing)
#prediction results applied to testing size from a Random Forest model with all variables
Pred_knn_rel
summary(Pred_knn_rel)
#comparing prediction with real values: RMSE 315.1408050, Rsquared 0.8164688, MAE 181.1566138
postResample(Pred_knn_rel,testing$Volume)
